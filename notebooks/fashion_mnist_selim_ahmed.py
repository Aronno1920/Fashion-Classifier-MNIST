# -*- coding: utf-8 -*-
"""Fashion_MNIST_Selim_Ahmed.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mi7jF7Ub0W7bXbakHKH1NtjHvCWuaod3

# **Image Classification with NN vs CNN**
Compare the performance of a basic Neural Network (NN) and a Convolutional Neural Network (CNN) on the Fashion MNIST dataset.<br>

Submitted by: *Selim Ahmed*<br>
AI Engineering - Batch 1

## Import required library
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# tensorflow related
import tensorflow as tf
from tensorflow.keras import Input
from tensorflow.keras.models import Sequential
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization

# tensorflow fashion dataset
from tensorflow.keras.datasets import fashion_mnist

# Best epochs number using EarlyStopping & ModelCheckpoint
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau

"""## **Prepare Dataset**"""

# Load data
(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()

# Normalize pixel values
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

# For NN: Flattened input
x_train_nn = x_train.reshape(-1, 28 * 28)
x_test_nn = x_test.reshape(-1, 28 * 28)

# For CNN: Add channel dimension
x_train_cnn = x_train.reshape(-1, 28, 28, 1)
x_test_cnn = x_test.reshape(-1, 28, 28, 1)

# Class names
class_names = ["T-shirt/top", "Trouser", "Pullover", "Dress", "Coat", "Sandal", "Shirt", "Sneaker", "Bag", "Ankle boot"]

"""## **Exploratory Data Analysis (EDA)**

### Initial Inspection
"""

print("--- Dataset Initial Inspection ---")
print(f"Training images shape -> {x_train.shape}")
print(f"Test images shape -> {x_test.shape}")
print(f"Image shape (single sample) -> {x_train[0].shape}")

print(f"\nData type of training images -> {x_train.dtype}")
print(f"Data type of training labels -> {y_train.dtype}")

print(f"\nMinimum pixel value in training images -> {np.min(x_train)}")
print(f"Maximum pixel value in training images -> {np.max(x_train)}")

"""### Pixel Value Distribution"""

# --- Before Normalization ---
print("\nPixel Value Distribution (Before Normalization)")
print(f"Min: {np.min(x_train)}, Max: {np.max(x_train)}, Mean: {np.mean(x_train):.2f}, Std: {np.std(x_train):.2f}")

plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.hist(x_train.flatten(), bins=50, color='gray', alpha=0.7)
plt.title('Before Normalization')
plt.xlabel('Pixel Value')
plt.ylabel('Frequency')
plt.grid(axis='y', alpha=0.75)

# --- After Normalization ---
x_train_norm = x_train / 255.0
print("\nAfter Normalization")
print(f"Min: {np.min(x_train_norm)}, Max: {np.max(x_train_norm)}, Mean: {np.mean(x_train_norm):.2f}, Std: {np.std(x_train_norm):.2f}")

plt.subplot(1, 2, 2)
plt.hist(x_train_norm.flatten(), bins=50, color='skyblue', alpha=0.7)
plt.title('After Normalization')
plt.xlabel('Pixel Value (0â€“1)')
plt.ylabel('Frequency')
plt.grid(axis='y', alpha=0.75)

plt.suptitle("Pixel Intensity Distribution: Before vs After Normalization", fontsize=14)
plt.tight_layout()
plt.show()

"""### Image Visualization"""

# Define class names (if not already defined)
class_names = ["T-shirt/top", "Trouser", "Pullover", "Dress", "Coat","Sandal", "Shirt", "Sneaker", "Bag", "Ankle boot"]

plt.figure(figsize=(10, 10))
for i in range(15): # Display 25 random images
    plt.subplot(5, 5, i + 1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(x_train[i], cmap=plt.cm.binary) # Use original x_train for visualization
    plt.xlabel(class_names[y_train[i]])
plt.suptitle('Sample Fashion MNIST Images and Labels')
plt.show()

"""### Class Distribution"""

# Count occurrences of each label in the training set
unique_labels, counts = np.unique(y_train, return_counts=True)
label_counts = dict(zip(unique_labels, counts))

# Count occurrences of each label in the test set (optional, but good practice)
unique_labels_test, counts_test = np.unique(y_test, return_counts=True)
label_counts_test = dict(zip(unique_labels_test, counts_test))


# Countplot of Training Data
df = pd.DataFrame({'label': y_train})
plt.figure(figsize=(10, 5))
sns.countplot(x='label', data=df, palette='viridis', hue='label', legend=False)
plt.title("Distribution of Classes in Training Data")
plt.xlabel("Clothing Item Category")
plt.ylabel("Number of Images")
plt.xticks(ticks=range(10), labels=class_names, rotation=45)
plt.grid(True, linestyle='--', alpha=0.3)
plt.tight_layout()
plt.show()


# Print combined distribution
print("\nClass distribution (Training & Test):")
for label in sorted(label_counts.keys()):
    train_count = label_counts.get(label, 0)
    test_count = label_counts_test.get(label, 0)
    print(f"{label}. {class_names[label]} image count -> Training: {train_count} & Test: {test_count}")

"""## **Build Models**

### Neural Network (NN)
"""

print("--- Building and Training Neural Network (NN) with Callbacks ---")
nn_model = Sequential([
    Input(shape=(784,)),
    Dense(256, activation='relu'),
    BatchNormalization(),
    Dropout(0.3),

    Dense(128, activation='relu'),
    BatchNormalization(),
    Dropout(0.3),

    Dense(64, activation='relu'),
    Dropout(0.2),

    Dense(10, activation='softmax')
])

nn_model.compile(optimizer='adam',
                 loss='sparse_categorical_crossentropy',
                 metrics=['accuracy'])

print("\nNN Model Architecture:")
nn_model.summary()

# --- Start: Callbacks ---
early_stopping_nn = EarlyStopping(
    monitor='val_accuracy',
    patience=5,
    restore_best_weights=True,
    verbose=1
)

checkpoint_filepath_nn = 'best_nn_model.keras'

model_checkpoint_nn = ModelCheckpoint(
    filepath=checkpoint_filepath_nn,
    monitor='val_accuracy',
    save_best_only=True,
    mode='max',
    verbose=1
)

lr_scheduler = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,
    patience=5,
    min_lr=1e-5,
    verbose=1)
# --- End: Callbacks ---

print("\nTraining NN Model with EarlyStopping and ModelCheckpoint...")
nn_history = nn_model.fit(
    x_train_nn, y_train,
    epochs=50,
    batch_size=64,
    validation_split=0.2,
    callbacks=[early_stopping_nn, model_checkpoint_nn, lr_scheduler],
    verbose=2
)

print("\nNN Model training complete.")
nn_model.load_weights(checkpoint_filepath_nn)

"""### Convolutional Neural Network (CNN)"""

print("--- Building and Training Convolutional Neural Network (CNN) with Callbacks ---")

cnn_model = Sequential([
    Input(shape=(28, 28, 1)),

    Conv2D(32, (3, 3), activation='relu', padding='same'),
    BatchNormalization(),
    MaxPooling2D((2, 2)),
    Dropout(0.25),

    Conv2D(64, (3, 3), activation='relu', padding='same'),
    BatchNormalization(),
    MaxPooling2D((2, 2)),
    Dropout(0.25),

    Conv2D(128, (3, 3), activation='relu', padding='same'),
    BatchNormalization(),
    MaxPooling2D((2, 2)),
    Dropout(0.4),

    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.3),
    Dense(10, activation='softmax')
])


cnn_model.compile(optimizer='adam',
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])

print("\nCNN Model Architecture:")
cnn_model.summary()

# --- Start: Callbacks ---
early_stopping_cnn = EarlyStopping(
    monitor='val_accuracy',
    patience=5,
    restore_best_weights=True,
    verbose=1
)

checkpoint_filepath_cnn = 'best_cnn_model.keras'
model_checkpoint_cnn = ModelCheckpoint(
    filepath=checkpoint_filepath_cnn,
    monitor='val_accuracy',
    save_best_only=True,
    mode='max',
    verbose=1
)
# --- End: Callbacks ---

print("\nTraining CNN Model with EarlyStopping and ModelCheckpoint...")
cnn_history = cnn_model.fit(
    x_train_cnn, y_train,
    epochs=50,
    batch_size=64,
    validation_data=(x_test_cnn, y_test),
    callbacks=[early_stopping_cnn, model_checkpoint_cnn],
    verbose=2
)

print("\nCNN Model training complete.")
cnn_model.load_weights(checkpoint_filepath_cnn)

"""## **Evaluate and Compare Performance**



"""

# Evaluate models on the test set with restored best weights
nn_test_loss, nn_test_acc = nn_model.evaluate(x_test_nn, y_test, verbose=0)
cnn_test_loss, cnn_test_acc = cnn_model.evaluate(x_test_cnn, y_test, verbose=0)

# Print comparison table
print("\nFinal Model Evaluation on Test Set")
print(f"{'Model':<10} {'Loss':>10} {'Accuracy':>12}")
print(f"{'-'*34}")
print(f"{'NN':<10} {nn_test_loss:>10.4f} {nn_test_acc:>12.4f}")
print(f"{'CNN':<10} {cnn_test_loss:>10.4f} {cnn_test_acc:>12.4f}")

"""## **Sample Predictions**"""

def plot_sample_predictions(model, x_data, y_true, reshape=False):
    predictions = model.predict(x_data)
    plt.figure(figsize=(10, 5))
    for i in range(5):
        plt.subplot(1, 5, i+1)
        img = x_data[i].reshape(28,28) if reshape else x_data[i].reshape(28,28)
        plt.imshow(img, cmap='gray')
        pred_label = np.argmax(predictions[i])
        true_label = y_true[i]
        color = 'green' if pred_label == true_label else 'red'
        plt.title(f"Pred: {class_names[pred_label]}\nTrue: {class_names[true_label]}", color=color)
        plt.axis('off')
    plt.tight_layout()
    plt.show()

print("NN Sample Predictions:")
plot_sample_predictions(nn_model, x_test_nn, y_test, reshape=True)

print("\n\n\nCNN Sample Predictions:")
plot_sample_predictions(cnn_model, x_test_cnn, y_test, reshape=True)

"""## **Plot Training History**"""

# (Optional) Plot training history (loss/accuracy)
print("\n--- Plotting Training History ---")

plt.figure(figsize=(12, 5))

# Plot NN training history
plt.subplot(1, 2, 1)
plt.plot(nn_history.history['accuracy'], label='NN Training Accuracy')
plt.plot(nn_history.history['val_accuracy'], label='NN Validation Accuracy')
plt.title('NN Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(nn_history.history['loss'], label='NN Training Loss')
plt.plot(nn_history.history['val_loss'], label='NN Validation Loss')
plt.title('NN Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.tight_layout()
plt.show()

# Plot CNN training history
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(cnn_history.history['accuracy'], label='CNN Training Accuracy')
plt.plot(cnn_history.history['val_accuracy'], label='CNN Validation Accuracy')
plt.title('CNN Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(cnn_history.history['loss'], label='CNN Training Loss')
plt.plot(cnn_history.history['val_loss'], label='CNN Validation Loss')
plt.title('CNN Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.tight_layout()
plt.show()

print("\nProject execution complete. The comparison and visualizations are displayed above.")

"""## Final Comparison"""

print(f"--- Final Comparison ---")
print(f"NN Test Accuracy -> {nn_test_acc:.4f}")
print(f"CNN Test Accuracy -> {cnn_test_acc:.4f}")
print(f"Accuracy Different (CNN-NN) -> ", cnn_test_acc-nn_test_acc)
print(f"\nCNN performed better than NN by {((cnn_test_acc - nn_test_acc) * 100):.2f}% accuracy.")